<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yunfei  Huang | Langevin Dynamics for Bayesian Inference</title>
    <meta name="author" content="Yunfei  Huang" />
    <meta name="description" content="stochastic differential equation, Fokker Plank equation, and their connections to Bayesian inference" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚓</text></svg>">
    <link rel="stylesheet" href="/Yunfei-Huang0.github.io/assets/css/main.css">
    <link rel="canonical" href="https://yunfei-huang0.github.io/Yunfei-Huang0.github.io/blog/2020/langevin-dynamics/">
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://yunfei-huang0.github.io/Yunfei-Huang0.github.io//"><span class="font-weight-bold">Yunfei</span>   Huang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/Yunfei-Huang0.github.io/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/Yunfei-Huang0.github.io/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/Yunfei-Huang0.github.io/publications/">publications</a>
              </li>
            </ul>
          </div>
       </div>
      </nav>

    <!-- Scrolling Progress Bar -->
    <div class="progress-container fixed-top">
      <div class="progress-bar" id="myBar"></div>
    </div>

    <!-- Reading progress bar -->

    <!-- Javascript for Progress Bar -->
    <script type="text/javascript">
      window.onscroll = function() {myFunction()};

      function myFunction() {
        var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
        var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
        var scrolled = (winScroll / height) * 100;
        document.getElementById("myBar").style.width = scrolled + "%";
      }
    </script>
      
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Langevin Dynamics for Bayesian Inference</h1>
    <p class="post-meta">September 6, 2020</p>
    <p class="post-tags">
      <a href="/Yunfei-Huang0.github.io//blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a>

    </p>
  </header>

  <article class="post-content">
    <p>In this post we visit some technical details centered around Langevin Dynamics in the context of stochastic Bayesian learning, assuming minimal background on conventional calculus and Brownian motion. Starting with quadratic variation, we gradually show how Ito’s Lemma and Fokker-Planck equation can be derived. Using Fokker-Planck equation, it is revealed that an Langevian dynamic can be used as a MCMC method to generate samples from an un-normalized distribution. Lastly, <a href="https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf" target="_blank" rel="noopener noreferrer">stochastic gradient Langevin dynamics</a> method is discussed.</p>

<p>The following materials are taken as references:</p>

<ul>
  <li><a href="https://www.math.ucdavis.edu/~hunter/m280_09/ch5.pdf" target="_blank" rel="noopener noreferrer">UC-Davis Lecture Notes on Applied Mathematics</a></li>
  <li><a href="https://www.youtube.com/watch?v=PPl-7_RL0Ko" target="_blank" rel="noopener noreferrer">MIT Topics in Mathematics with Applications in Finance Lecture 17: Stochastic Processes II</a></li>
  <li><a href="https://www.youtube.com/watch?v=Z5yRMMVUC5w" target="_blank" rel="noopener noreferrer">MIT Topics in Mathematics with Applications in Finance Lecture 18: Itō Calculus</a></li>
</ul>

<h2 id="quadratic-variation">Quadratic Variation</h2>
<p>For Brownian motion \(B_t\), 
we know that \(B\left(\frac{i+1}{N}T\right) - B\left(\frac{i}{N}T\right)\) for different index \(i\) are i.i.d. with distribution \(\mathcal{N}\left(0, \frac{T}{N}\right)\). The following holds by strong law of large numbers.</p>

\[\begin{align*}
\lim_{N\to\infty}\sum_{i=1}^N \left(B\left(\frac{i+1}{N}T\right) - B\left(\frac{i}{N}T\right)\right)^2&amp;=T \text{ a.s.} \\
\end{align*}\]

<p>The above can be written in differential form as</p>

\[\begin{align*}
\int (dB)^2 &amp;= \int dt\\
(dB)^2 &amp;= dt\\
\end{align*}\]

<p>which is known as quadratic variation. This means that the second order term of Taylor expansion involving \(B_t\) scales as \(O(t)\) instead of \(o(t)\), the implication of which is detailed in Ito’s Lemma below.</p>

<h2 id="itos-lemma">Ito’s Lemma</h2>

<p>Suppose we want to compute \(f(B_t)\) for some smooth function \(f\). By Taylor expansion, the infinitesimal difference can be expressed as</p>

\[\begin{align*}
f(B_{t+\Delta t}) - f(B_t) &amp;= f'(B_t) (B_{t+\Delta t} - B_t) + \frac{f''(B_t)}{2}\left(B_{t+\Delta t}-B_t\right)^2 \\
                  \text{(differential form) }      df &amp;= f'(B_t) dB_t + \frac{f''(B_t)}{2}\left(dB_t\right)^2 \\
                  \text{(quadratic variation) }      df &amp;= f'(B_t) dB_t + \frac{f''(B_t)}{2} dt\\
                       \frac{df}{dt} &amp;= f'(B_t) \frac{dB_t}{dt} \color{red}{+ \frac{f''(B_t)}{2}}
\end{align*}\]

<p>The above equation is a naive version of Ito’s Lemma, the basis of Ito’s calculus. Note how it differs from conventional calculus by having the second term in red, as a direct consequence of quadratic variation.</p>

<p>Let us now look at a more advanced version of Ito’s Lemma, with the goal of obtaining the differential form of \(f(x_t, t)\) where \(x_t\) is a stochastic process defined with the following stochastic differential equation</p>

\[\begin{align*}
dx_t = \mu(x_t)dt + \sigma dB_t
\end{align*}\]

<p>Similarly as before, let’s apply Taylor expansion on the infinitesimal difference of \(f\)</p>

\[\begin{align*}
f(x+\Delta x, t+\Delta t) - f(x, t) &amp;= \frac{\partial f}{\partial t} \Delta t + \frac{\partial f}{\partial x} \Delta x + \frac{1}{2}\left[
\frac{\partial^2 f}{\partial t^2}\Delta t^2 + 2\frac{\partial^2 f}{\partial t \partial x} \Delta t \Delta x + \frac{\partial^2 f}{\partial x^2}(\Delta x)^2
\right] \\
\text{(differential form) } d f &amp;= \frac{\partial f}{\partial t}dt + \frac{\partial f}{\partial x} dx_t +\frac{1}{2}\left[
o(dt) + o(dt) + \frac{\partial^2 f}{\partial x^2}(dx_t)^2
\right] \\
\text{(substitute $dx_t$) } d f &amp;= \frac{\partial f}{\partial t}dt + \frac{\partial f}{\partial x} (\mu(x_t)dt +\sigma dB_t) +\frac{1}{2}
\frac{\partial^2 f}{\partial x^2}(\mu(x_t)^2(dt)^2 + 2\mu(x_t)\sigma dt dB_t + \sigma^2 (dB_t)^2)
\\
\text{(quadratic variation) } d f &amp;= \left(\frac{\partial f}{\partial t} + \mu(x_t)\frac{\partial f}{\partial x} + \color{red}{\frac{1}{2}\sigma^2\frac{\partial^2 f}{\partial x^2}}\right)dt + \sigma\frac{\partial f}{\partial x} dB_t
\end{align*}\]

<p>Again, the red term highlights the difference to conventional calculus. In the special when \(f\) is not a function of \(t\), the above can be reduced to</p>

\[\begin{align*}
 d f &amp;= \left(\mu(x_t)f'(x) + \color{red}{\frac{1}{2}\sigma^2 f''(x)}\right)dt + \sigma f'(x) dB_t,
\end{align*}\]

<p>which is used in the derivation of Fokker-Planck equation in the next section.</p>

<h2 id="fokker-planck-equation">Fokker-Planck equation</h2>

<p>For a stochastic process \(x\) that is defined as \(dx_t = \mu(x_t) dt + \sigma dB_t\), we are interested in how the distribution \(p_t\) of \(x_t\) evolves over time. For an arbitrary smooth function \(f\), the following holds</p>

\[\begin{align*}
\frac{d}{dt}\mathbb{E}\left[f(x_t)\right] = \left\{
\begin{array}{ll}
\int f(x) \frac{d}{dt}p_t(x) dx &amp; \text{ $f(x)$ viewed as a function of $x$ sampled from $p_t$} \\
\mathbb{E}\left[\frac{d}{dt}f(x_t)\right] &amp; \text{ $f(x_t)$ viewed as a function of stochastic process $x_t$}\\
\end{array}
\right.
\end{align*}\]

<p>The second expression can be evaluated with Ito’s Lemma.</p>

\[\begin{align*}
&amp;\mathbb{E}\left[\frac{d}{dt}f(x_t)\right]\\
\text{(Ito's Lemma) }=&amp;\mathbb{E}\left[\mu(x_t)f'(x_t)+\frac{1}{2}\sigma^2f''(x_t) + \sigma f'(x_t) \frac{dB_t}{dt}\right] \\
\text{($dB_t$ has mean $0$) }=&amp;\mathbb{E}\left[\mu(x_t)f'(x_t)+\frac{1}{2}\sigma^2f''(x_t) \right] \\
\text{(using $x_t\sim p_t$) }=&amp;\int\left[\mu(x)f'(x)+\frac{1}{2}\sigma^2f''(x) \right]p_t(x)dx \\
\text{(integration by part) }=&amp;-\int f(x)\frac{\partial (\mu(x)p_t(x)) }{\partial x}dx+\frac{1}{2}\sigma^2\int f(x)\frac{\partial^2 p_t(x)}{\partial x^2} p_t(x)dx
\end{align*}\]

<p>Combining the above two and cancelling out the arbitrary function \(f\), we obtain Fokker-Planck equation below.</p>

\[\begin{align*}
\frac{d}{dt}p_t = -\frac{\partial}{\partial x}\left(\mu(x)p_t(x)\right)+\frac{1}{2}\sigma^2\frac{\partial^2}{\partial x^2}p_t(x)
\end{align*}\]

<h2 id="langevin-dynamics">Langevin Dynamics</h2>

<p>let \(\mu(x) = -u'(x)\) for some function \(u(x)\), then the corresponding stochastic process is defined as \(dx_t = -u'(x_t) dt + \sigma dB_t\), often referred as over-damped Langevin process. Using Fokker-Planck equation, we know that</p>

\[\begin{align*}
p(x) \propto e^{-2/\sigma^2 u(x)}
\end{align*}\]

<p>is the stationary distribution of \(x_t\).</p>

\[\begin{align*}
&amp;\frac{\partial}{\partial x}\left(u'(x)p(x)\right)+\frac{1}{2}\sigma^2\frac{\partial^2}{\partial x^2}p(x) \\
=&amp;u''(x)p(x)-\frac{2}{\sigma^2}(u'(x))^2 p(x) + \frac{1}{2}\sigma^2\left(-\frac{2}{\sigma^2}u''(x)p(x) + \frac{4}{\sigma^4}(u'(x))^2 p(x)\right)=0
\end{align*}\]

<h3 id="langevin-mcmc">Langevin MCMC</h3>

<p>The fact that Langevin process \(dx_t = -u'(x_t) dt + \sigma dB_t\) converges to a stationary distribution \(p(x) \propto e^{-2/\sigma^2 u(x)}\) lends itself as a suitable Markov chain Monte Carlo method. Specifically, to obtain samples from a un-normalized density function \(\bar{p}(x)\), we just need to run the following Langevin process from a random starting point till it reaches steady state distribution</p>

\[\begin{align*}
dx_t = \nabla_x \log \bar{p}(x) dt + \sqrt{2} dB_t
\end{align*}\]

<p>Discretized sample path of Langevin process can be generated with Euler method</p>

\[\begin{align*}
x_{k+1}  = x_k  + \nabla_x \log \bar{p}(x_k) \epsilon + \sqrt{2\epsilon}\xi_k
\end{align*}\]

<p>Since the discretization is only an approximation to the original continuous stochastic process, it does not in itself lead to desired stationary distribution (unless \(\epsilon\) becomes infinitesimal) and thus should be corrected by Metropolis-Hastings to enforce detailed balance condition.</p>

<p>One lingering question is: does the discretization of Langevin dynamics satisfy detailed balance equation in \(\epsilon\to0\) asymptote? The fact that it converges to a desirable distribution does not indicate that it is a time-reversible Markov chain. Even thought it is claimed by some source that the asymptotic acceptance ratio approaches 1, I was not able to show that it is the case and is stuck at the following derivation.</p>

\[\begin{align*}
&amp;\frac{\bar{p}(x)P(x\to x')}{\bar{p}(x')P(x'\to x)} = \frac{
\bar{p}(x)\mathcal{N}\left(x'-x-\nabla_x \bar{p}(x)\tau|0, 2\tau\right)
}{
\bar{p}(x')\mathcal{N}\left(x-x'-\nabla_x \bar{p}(x')\tau|0, 2\tau\right)
}\\
=&amp; 
\frac{
\bar{p}(x)e^{(x'-x)\nabla_x \bar{p}(x)/2 + o(\tau)}
}{
\bar{p}(x')e^{(x-x')\nabla_x \bar{p}(x')/2 + o(\tau)} 
}
=
\frac{
\bar{p}(x)e^{(x'-x)\nabla_x \frac{\bar{p}(x)+\bar{p}(x')}{2} + o(\tau)}
}{
\bar{p}(x') 
}
\end{align*}\]

<h3 id="relevance-to-bayesian-inference">Relevance to Bayesian Inference</h3>

<p>In Bayesian inference we deal with a prior distribution \(p_\text{prior}(\theta)\) for some latent parameter \(\theta\) and a likelihood term \(p_\text{likelihood}(\mathcal{D}\|\theta)\) of the dataset \(\mathcal{D}\) given the latent parameter, and the goal is to obtain samples according to the posterior probability \(p_\text{post}(\theta\|\mathcal{D}) = p_\text{prior}(\theta)p_\text{likelihood}(\mathcal{D}\|\theta)/p(\mathcal{D})\). Since the constant marginal likelihood term \(p(\mathcal{D})=\int p_\text{likelihood}(\mathcal{D}\|\theta)p_\text{prior}(\theta)d\theta\) is often intractable, we are left with a un-normalized poster probability \(p_\text{post}\propto p_\text{prior}p_\text{likelihood}\). To sample from it, we can simply construct and run the following stochastic process</p>

\[\begin{align*}
d\theta_t = \left(\nabla_\theta \log p_\text{prior}(\theta) + \nabla_\theta \log p_\text{likelihood}(\mathcal{D}|\theta)\right) dt + \sqrt{2} dB_t
\end{align*}\]

<p>Hereafter we use the notation of \(x\) to indicate elements in the dataset \(x\in\mathcal{D}\), \(\theta\) to denote the hidden parameter for which we want to conduct Bayesian inference, and drop the subscript to different \(p\) as they can be differentiated by their arguments.</p>

<h2 id="stochastic-gradient-langevin-dynamics-sgld">Stochastic Gradient Langevin Dynamics (SGLD)</h2>

<p>Discretizing Langevin dynamics with step size of \(\epsilon_t\) leads to the following update rule</p>

\[\begin{align*}
\Delta \theta = \epsilon_t \left(\nabla_\theta \log p(\theta) + \nabla_\theta \log p(\mathcal{D}|\theta)\right) + \sqrt{2 \epsilon_t} \xi_t, \text{ where }\xi_t\sim\mathcal{N}(0, 1)
\end{align*}\]

<p>If we have \(\sum_t\epsilon_t = \infty\) and \(\sum_t\epsilon^2 &lt;\infty\) then asymptotically the discretization error will become negligible and the update rule approaches the corresponding Langevin dyanmics, resulting in a sequence of \(\theta_t\) that converges to the posterior distribution \(p(\theta\|\mathcal{D})\).</p>

<p>An interesting and clever observation made by <a href="https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf" target="_blank" rel="noopener noreferrer">stochastic gradient Langevin dynamics</a> paper is that the convergence will hold even if we use mini-batches of the data to estimate the gradient of \(\nabla_\theta \log p(\mathcal{D}\|\theta)\).</p>

\[\begin{align*}
\nabla_\theta \log p(\mathcal{D}|\theta) \approx \frac{N}{n}\sum_{i=1}^n\nabla_\theta \log p(x_{t,i}|\theta)
\end{align*}\]

<p>The insight is that the stochastic error introduced from using mini-batches instead of the whole dataset dies out much faster than the added Gaussian noise as the \(\epsilon_t\) decreases, so it does not change the asymptotical behavior of the update rule. Specifically, the randomness coming from the stochastic estimate of \(\nabla_\theta \log p(\mathcal{D}\|\theta)\) has a variance that scales as \(\epsilon_t^2\) since it is multiplied with \(\epsilon_t\). In comparison, the variance of the added Gaussian noise scales linearly as \(\epsilon_t\).</p>

\[\begin{align*}
\Delta \theta =\underbrace{ \underbrace{ \underbrace{\epsilon_t \frac{N}{n}\sum_{i=1}^n\nabla_\theta \log p(x_{t, i}|\theta)}_{\text{gradient step towards ML target}} +\epsilon_t \nabla_\theta \log p(\theta)}_{\text{gradient step towards MAP target}} + \sqrt{2 \epsilon_t} \xi_t}_{\text{stochastic gradient Langevin dynamics for posterior sampling}} , \text{ where }\xi_t\sim\mathcal{N}(0, 1)
\end{align*}\]

<p>Given that stochastic Langevin dynamics converges to the desired distribution as \(\epsilon_t\to0\), we do not need to carry out Metropolis-Hastings to reject samples. This is crucial in simplifying the algorithm, since evaluation of rejection/acceptance rate is computed at every step and it depends on the evaluation of \(p(\theta)p(\mathcal{D}\|\theta)\) which can only be computed after traversing the whole dataset.</p>

<p>As a closing remark, if we use the posterior sampling for the estimation of the expectation of some function \(f\), it is recommended in <a href="https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf" target="_blank" rel="noopener noreferrer">stochastic gradient Langevin dynamics</a> that the following equation be used.</p>

\[\begin{align*}
\mathbb{E}[f(\theta)] = \frac{\sum_t \epsilon_t f(\theta_t)}{\sum_t \epsilon_t}
\end{align*}\]

<p>with the intuition that each \(\theta_t\) contributes an effective sample size proportional to \(\epsilon_t\).</p>


  </article><div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname  = 'yyang768osu-github-io';
      var disqus_identifier = '/blog/2020/langevin-dynamics';
      var disqus_title      = "Langevin Dynamics for Bayesian Inference";
      (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript" target="_blank" rel="noopener noreferrer">comments powered by Disqus.</a>
</noscript>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2022 Yunfei  Huang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.
Last updated: March 27, 2022.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/Yunfei-Huang0.github.io/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/Yunfei-Huang0.github.io/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/Yunfei-Huang0.github.io/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123722738-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-123722738-1');
  </script>
  </body>
</html>

