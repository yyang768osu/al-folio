<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yang  Yang | publications</title>
    <meta name="author" content="Yang  Yang" />
    <meta name="description" content="* indicates equal contribution." />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚓</text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://yyang768osu.github.io/publications/">
  </head>

  <!-- Body -->
  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://yyang768osu.github.io/"><span class="font-weight-bold">Yang</span>   Yang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
            </ul>
          </div>
       </div>
      </nav>

    <!-- Scrolling Progress Bar -->
    <div class="progress-container fixed-top">
      <div class="progress-bar" id="myBar"></div>
    </div>

    <!-- Reading progress bar -->

    <!-- Javascript for Progress Bar -->
    <script type="text/javascript">
      window.onscroll = function() {myFunction()};

      function myFunction() {
        var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
        var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
        var scrolled = (winScroll / height) * 100;
        document.getElementById("myBar").style.width = scrolled + "%";
      }
    </script>
      
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">* indicates equal contribution.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2022</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ICLR</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/transformer_transform-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/transformer_transform-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/transformer_transform-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/transformer_transform.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="zhu2022transformerbased" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Transformer-based Transform Coding</div>
          <!-- Author -->
          <div class="author">
<a href="https://yinhaoz.github.io/" target="_blank" rel="noopener noreferrer">Zhu, Yinhao*</a>, 
                  <em>Yang, Yang*</em>, and <a href="https://tacocohen.wordpress.com/" target="_blank" rel="noopener noreferrer">Cohen, Taco</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In International Conference on Learning Representations (ICLR)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=IDwN6xjHnK8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Neural data compression based on nonlinear transform coding has made great progress over the last few years, mainly due to improvements in prior models, quantization methods and nonlinear transforms. A general trend in many recent works pushing the limit of rate-distortion performance is to use ever more expensive prior models that can lead to prohibitively slow decoding. Instead, we focus on more expressive transforms that result in a better rate-distortion-computation trade-off. Specifically, we show that nonlinear transforms built on Swin-transformers can achieve better compression efficiency than transforms built on convolutional neural networks (ConvNets), while requiring fewer parameters and shorter decoding time. Paired with a compute-efficient Channel-wise Auto-Regressive Model prior, our SwinT-ChARM model outperforms VTM-12.1 by 3.68 % in BD-rate on Kodak with comparable decoding speed. In P-frame video compression setting, we are able to outperform the popular ConvNet-based scale-space-flow model by 12.35 % in BD-rate on UVG. We provide model scaling studies to verify the computational efficiency of the proposed solutions and conduct several analyses to reveal the source of coding gain of transformers over ConvNets, including better spatial decorrelation, flexible effective receptive field, and more localized response of latent pixels during progressive decoding.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>A swin-transformer based auto-encoder structure is proposed that achieves SOTA in rate-distortion-complexity trade-off of image compression. It also outperforms SSF in video compression. AFAIK SwinT-ChARM is the first neural image codec that outperforms VTM in rate-distortion while with comparable decoding time on GPU.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ICIP</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/quantization_levels_and_packets-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/quantization_levels_and_packets-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/quantization_levels_and_packets-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/quantization_levels_and_packets.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="plonq" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Progressive Neural Image Compression With Nested Quantization And Latent Ordering</div>
          <!-- Author -->
          <div class="author">
<a href="https://www.ics.uci.edu/~yadongl1/" target="_blank" rel="noopener noreferrer">Lu, Yadong*</a>, <a href="https://yinhaoz.github.io/" target="_blank" rel="noopener noreferrer">Zhu, Yinhao*</a>, 
                  <em>Yang, Yang*</em>, <a href="https://scholar.google.com/citations?user=iRTzPLoAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Said, Amir</a>, and <a href="https://tacocohen.wordpress.com/" target="_blank" rel="noopener noreferrer">Cohen, Taco S</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE International Conference on Image Processing (ICIP)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ieeexplore.ieee.org/document/9506026" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We present PLONQ, a progressive neural image compression scheme which pushes the boundary of variable bitrate compression by allowing quality scalable coding with a single bitstream. In contrast to existing learned variable bitrate solutions which produce separate bitstreams for each quality, it enables easier rate-control and requires less storage. Leveraging the latent scaling based variable bitrate solution, we introduce nested quantization, a method that defines multiple quantization levels with nested quantization grids, and progressively refines all latents from the coarsest to the finest quantization level. To achieve finer progressiveness in between any two quantization levels, latent elements are incrementally refined with an importance ordering defined in the rate-distortion sense. To the best of our knowledge, PLONQ is the first learning-based progressive image coding scheme and it outperforms SPIHT, a well-known wavelet-based progressive image codec.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>A prefix-decodable bitstream (lower bitrate stream is embedded as a prefix of higher bitrate stream) is obtained with nested quantization and per-element sorting by prior stddev, based on the hyperprior model.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">JSP</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/YUV-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/YUV-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/YUV-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/YUV.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="prelu_nogdn" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Transform Network Architectures for Deep Learning Based End-to-End Image/Video Coding in Subsampled Color Spaces</div>
          <!-- Author -->
          <div class="author">
<a href="https://www.linkedin.com/in/hilmi-enes-egilmez-2ab4b11a" target="_blank" rel="noopener noreferrer">Egilmez, Hilmi</a>, Singh, Ankitesh Kumar, Coban, Muhammed, Karczewicz, Marta, <a href="https://yinhaoz.github.io/" target="_blank" rel="noopener noreferrer">Zhu, Yinhao</a>, 
                  <em>Yang, Yang</em>, <a href="https://scholar.google.com/citations?user=iRTzPLoAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Said, Amir</a>, and <a href="https://tacocohen.wordpress.com/" target="_blank" rel="noopener noreferrer">Cohen, Taco</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE Open Journal of Signal Processing</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9464274" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Most of the existing deep learning based end-to-end image/video coding (DLEC) architectures are designed for non-subsampled RGB color format. However, in order to achieve a superior coding performance, many state-of-the-art block-based compression standards such as High Efficiency Video Coding (HEVC/H.265) and Versatile Video Coding (VVC/H.266) are designed primarily for YUV 4:2:0 format, where U and V components are subsampled by considering the human visual system. This paper investigates various DLEC designs to support YUV 4:2:0 format by comparing their performance against the main profiles of HEVC and VVC standards under a common evaluation framework. Moreover, a new transform network architecture is proposed to improve the efficiency of coding YUV 4:2:0 data. The experimental results on YUV 4:2:0 datasets show that the proposed architecture significantly outperforms naive extensions of existing architectures designed for RGB format and achieves about 10% average BD-rate improvement over the intra-frame coding in HEVC.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>PReLU can replace GDN in the hyperprior model to compress YUV (and RGB!) images without loss of coding gain.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">CVPR-W</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/PSC-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/PSC-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/PSC-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/PSC.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="psc" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Phase Selective Convolution</div>
          <!-- Author -->
          <div class="author">
<a href="https://www.linkedin.com/in/jmjlin/" target="_blank" rel="noopener noreferrer">Lin, Jamie Menjay</a>, Noorzad, Parham, 
                  <em>Yang, Yang</em>, Kwak, Nojun, and Porikli, Fatih
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops on Embedded Vision</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2021W/EVW/html/Lin_Phase_Selective_Convolution_CVPRW_2021_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper introduces Phase Selective Convolution (PSC), an enhanced convolution for more deliberate utilization of activations in convolutional networks. Unlike conventional use of convolutions with activation functions, PSC preserves the full space of activations while supporting desirable model nonlinearity. Similar to several other network operations, e.g., the ReLU operation, at the time of their introduction, PSC may not execute as efficiently on platforms without hardware specialization support. As a first step in addressing the need for optimization, we propose a hardware acceleration scheme to enable the intended efficiency for PSC execution. Moreover, we propose a PSC deployment strategy, with which PSC is applied only to selected layers of the networks, to avoid excessive increase in the total model size. To evaluate the results, we apply PSC as a drop-in replacement for selected convolution layers in several networks without affecting their macro network architectures. In particular, PSC-enhanced ResNets achieve higher accuracies by 1.0-2.0% and 0.7-1.0% on CIFAR-100 and ImageNet, respectively, in Pareto efficiency. PSC-enhanced MobileNets (V2 and V3 Large) and MobileNetV3 (Small) achieve 0.9-1.0% and 1.8% accuracy gains, respectively, on ImageNet at little (0.2-0.7%) total model size increase.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>A simple and effective extension of Conv+ReLU that can achieve better pareto efficiency in image classification when compared with ResNet and MobileNets</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ICASSP</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/feedback-recurrent-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/feedback-recurrent-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/feedback-recurrent-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/feedback-recurrent.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="9054074" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Feedback Recurrent Autoencoder</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, <a href="https://naifrec.github.io/" target="_blank" rel="noopener noreferrer">Sautière, Guillaume</a>, <a href="https://jongharyu.github.io/" target="_blank" rel="noopener noreferrer">Ryu, J. Jon</a>, and <a href="https://tacocohen.wordpress.com/" target="_blank" rel="noopener noreferrer">Cohen, Taco S</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ieeexplore.ieee.org/document/9054074" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this work, we propose a new recurrent autoencoder architecture, termed Feedback Recurrent AutoEncoder (FRAE), for online compression of sequential data with temporal dependency. The recurrent structure of FRAE is designed to efficiently extract the redundancy along the time dimension and allows a compact discrete representation of the data to be learned. We demonstrate its effectiveness in speech spectrogram compression. Specifically, we show that the FRAE, paired with a powerful neural vocoder, can produce high-quality speech waveforms at a low, fixed bitrate. We further show that by adding a learned prior for the latent space and using an entropy coder, we can achieve an even lower variable bitrate.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>Extend VAE to sequential setting for efficient representation learning of sequential data. In the application of speech compression, when paired with a neural vocoder, the proposed FRAE signifantly outperforms Opus, an open source speech codec.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ACCV</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/VideoFRAE-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/VideoFRAE-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/VideoFRAE-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/VideoFRAE.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="Golinski_2020_ACCV" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Feedback Recurrent Autoencoder for Video Compression</div>
          <!-- Author -->
          <div class="author">
<a href="https://scholar.google.co.uk/citations?user=MnDZag8AAAAJ" target="_blank" rel="noopener noreferrer">Golinski, Adam*</a>, <a href="https://scholar.google.com/citations?user=BqNYf-oAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Pourreza, Reza*</a>, 
                  <em>Yang, Yang*</em>, <a href="https://naifrec.github.io/" target="_blank" rel="noopener noreferrer">Sautière, Guillaume</a>, and <a href="https://tacocohen.wordpress.com/" target="_blank" rel="noopener noreferrer">Cohen, Taco S</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Asian Conference on Computer Vision (ACCV)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openaccess.thecvf.com/content/ACCV2020/html/Golinski_Feedback_Recurrent_Autoencoder_for_Video_Compression_ACCV_2020_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recent advances in deep generative modeling have enabled efficient modeling of high dimensional data distributions and opened up a new horizon for solving data compression problems. Specifically, autoencoder based learned image or video compression solutions are emerging as strong competitors to traditional approaches. In this work, We propose a new network architecture, based on common and well studied components, for learned video compression operating in low latency mode. Our method yields competitive MS-SSIM/rate performance on the high-resolution UVG dataset, among both learned video compression approaches and classical video compression methods (H.265 and H.264) in the rate range of interest for streaming applications. Additionally, we provide an analysis of existing approaches through the lens of their underlying probabilistic graphical models.Finally, we point out issues with temporal consistency and color shift observed in empirical evaluation, and suggest directions forward to alleviate those.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>One of the early works that propose neural network based video codecs. A recurrent layer is introduced in the decoder to capture long-range redundancy of video content, the state of which is fed back to encoder.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">CVPR</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/GuidedVAE-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/GuidedVAE-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/GuidedVAE-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/GuidedVAE.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="Ding_2020_CVPR" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Guided Variational Autoencoder for Disentanglement Learning</div>
          <!-- Author -->
          <div class="author">Ding, Zheng*, <a href="https://yfxu.com/" target="_blank" rel="noopener noreferrer">Xu, Yifan*</a>, <a href="https://weijianxu.com/" target="_blank" rel="noopener noreferrer">Xu, Weijian</a>, Parmar, Gaurav, 
                  <em>Yang, Yang</em>, <a href="https://staff.fnwi.uva.nl/m.welling/" target="_blank" rel="noopener noreferrer">Welling, Max</a>, and <a href="https://pages.ucsd.edu/~ztu/" target="_blank" rel="noopener noreferrer">Tu, Zhuowen</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Ding_Guided_Variational_Autoencoder_for_Disentanglement_Learning_CVPR_2020_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose an algorithm, guided variational autoencoder (Guided-VAE), that is able to learn a controllable generative model by performing latent representation disentanglement learning. The learning objective is achieved by providing signal to the latent encoding/embedding in VAE without changing its main backbone architecture, hence retaining the desirable properties of the VAE. We design an unsupervised and a supervised strategy in Guided-VAE and observe enhanced modeling and controlling capability over the vanilla VAE. In the unsupervised strategy, we guide the VAE learning by introducing a lightweight decoder that learns latent geometric transformation and principal components; in the supervised strategy, we use an adversarial excitation and inhibition mechanism to encourage the disentanglement of the latent variables. Guided-VAE enjoys its transparency and simplicity for the general representation learning task, as well as disentanglement learning. On a number of experiments for representation learning, improved synthesis/sampling, better disentanglement for classification, and reduced classification errors in meta learning have been observed.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>An auxiliary decoder is used to improve the disentanglement of latent from a VAE.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ICML-W</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="tat" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Deep Generative Video Compression with Temporal Autoregressive Transforms</div>
          <!-- Author -->
          <div class="author">
<a href="https://buggyyang.github.io/" target="_blank" rel="noopener noreferrer">Yang, Ruihan</a>, <a href="https://yiboyang.com/about/" target="_blank" rel="noopener noreferrer">Yang, Yibo</a>, <a href="https://joelouismarino.github.io/" target="_blank" rel="noopener noreferrer">Marino, Joseph</a>, 
                  <em>Yang, Yang</em>, and <a href="http://www.stephanmandt.com/" target="_blank" rel="noopener noreferrer">Mandt, Stephan</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In ICML 2020 Workshop on Invertible Neural Networks, Normalizing Flows, andExplicit Likelihood Models</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://joelouismarino.github.io/files/papers/2020/seq_flows_compression/seq_flows_compression.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ICASSP</abbr><div class="teaser">
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/pub_img/GrammarAug-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/pub_img/GrammarAug-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/pub_img/GrammarAug-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/pub_img/GrammarAug.png" data-zoomable="">

  </picture>

</figure>
</div>

        </div>

        <!-- Entry bib key -->
        <div id="8682157" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Automatic Grammar Augmentation for Robust Voice Command Recognition</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, <a href="https://sites.google.com/a/eng.ucsd.edu/alalitha/" target="_blank" rel="noopener noreferrer">Lalitha, Anusha</a>, <a href="https://scholar.google.com/citations?user=lUYLvBgAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Lee, Jinwon</a>, and <a href="https://ieeexplore.ieee.org/author/37268926000" target="_blank" rel="noopener noreferrer">Lott, Chris</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="tldr btn btn-sm z-depth-0" role="button">TLDR</a>
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://ieeexplore.ieee.org/document/8682157" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper proposes a novel pipeline for automatic grammar augmentation that provides a significant improvement in the voice command recognition accuracy for systems with small footprint acoustic model (AM). The improvement is achieved by augmenting the user-defined voice command set, also called grammar set, with alternate grammar expressions. For a given grammar set, a set of potential grammar expressions (candidate set) for augmentation is constructed from an AM-specific statistical pronunciation dictionary that captures the consistent patterns and errors in the decoding of AM induced by variations in pronunciation, pitch, tempo, accent, ambiguous spellings, and noise conditions. Using this candidate set, greedy optimization based and cross-entropy-method (CEM) based algorithms are considered to search for an augmented grammar set with improved recognition accuracy utilizing a command-specific dataset. Our experiments show that the proposed pipeline along with algorithms considered in this paper significantly reduce the mis-detection and mis-classification rate without increasing the false-alarm rate. Experiments also demonstrate the consistent superior performance of CEM method over greedy-based algorithms.</p>
          </div>
<!-- Hidden tldr block -->
          <div class="tldr hidden">
            <p>Improve voice command recognition of a light-weight acoustic model by augmenting the target command to capture variations of inputs.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">INFOCOM</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="8737655" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Joint Antenna Allocation and Link Scheduling in FlexRadio Networks</div>
          <!-- Author -->
          <div class="author">
<a href="https://www.linkedin.com/in/zhenzhi-qian-5a350752/" target="_blank" rel="noopener noreferrer">Qian, Zhenzhi</a>, 
                  <em>Yang, Yang</em>, Srinivasan, Kannan, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE INFOCOM</em> 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/document/8737655" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">MobiHoc</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="10.1145/2942358.2942362" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Anonymous-Query Based Rate Control for Wireless Multicast: Approaching Optimality with Constant Feedback</div>
          <!-- Author -->
          <div class="author">
<a href="https://scholar.google.com/citations?user=KqQOfYEAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Wu, Fei</a>, 
                  <em>Yang, Yang</em>, Zhang, Ouyang, Srinivasan, Kannan, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 17th ACM International Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc)</em> 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/2942358.2942362" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>For a multicast group of n receivers, existing techniques either achieve high throughput at the cost of prohibitively large (e.g., O(n)) feedback overhead, or achieve low feedback overhead but without either optimal or near-optimal throughput guarantees. Simultaneously achieving good throughput guarantees and low feedback overhead has been an open problem and could be the key reason why wireless multicast has not been successfully deployed in practice. In this paper, we develop a novel anonymous-query based rate control, which approaches the optimal throughput with a constant feedback overhead independent of the number of receivers. In addition to our theoretical results, through implementation on a software-defined ratio platform, we show that the anonymous-query based algorithm achieves low-overhead and robustness in practice.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">JSAC</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="6991510" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Constant-Delay and Constant-Feedback Moving Window Network Coding for Wireless Multicast: Design and Asymptotic Analysis</div>
          <!-- Author -->
          <div class="author">
<a href="https://scholar.google.com/citations?user=KqQOfYEAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Wu, Fei</a>, <a href="http://webhome.auburn.edu/~yzs0078/" target="_blank" rel="noopener noreferrer">Sun, Yin</a>, 
                  <em>Yang, Yang</em>, Srinivasan, Kannan, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Journal on Selected Areas in Communications</em> 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/document/6991510" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">INFOCOM</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="7218602" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Scheduling in wireless networks with full-duplex cut-through transmission</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE INFOCOM</em> 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/document/7218602" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">CDC</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="7402446" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Dynamic user association and energy control in cellular networks with renewable resources</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, <a href="https://scholar.google.com/citations?user=5xtKlEkAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Liu, Jiashang</a>, Sinha, Prasun, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 54th IEEE Conference on Decision and Control (CDC)</em> 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/document/7402446" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">ToIT</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="delay_asymptotics" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Delay Asymptotics With Retransmissions and Incremental Redundancy Codes Over Erasure Channels</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, <a href="https://scholar.google.com/citations?hl=en&amp;user=m36rOvoAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="noopener noreferrer">Tan, Jian</a>, <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>, and Gamal, Hesham El
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>IEEE Transactions on Information Theory</em> 2014
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/abstract/document/6717177/similar#similar" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">INFOCOM</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="6847947" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Characterizing the achievable throughput in wireless networks with two active RF chains</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, <a href="https://scholar.google.com/citations?user=5KCBuEAAAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer">Chen, Bo</a>, Srinivasan, Kannan, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE INFOCOM</em> 2014
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/document/6847947" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">WiOpt</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="6850302" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A near-optimal randomized algorithm for uplink resource allocation in OFDMA systems</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, Nam, Changwon, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 12th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt)</em> 2014
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/document/6850302" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2012</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">MobiHoc</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="10.1145/2248371.2248391" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Throughput of Rateless Codes over Broadcast Erasure Channels</div>
          <!-- Author -->
          <div class="author">
                  <em>Yang, Yang</em>, and <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Thirteenth ACM International Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc)</em> 2012
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/10.1145/2248371.2248391" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we characterize the throughput of a broadcast network with n receivers using rateless codes with block size K. We assume that the underlying channel is a Markov modulated erasure channel that is i.i.d. across users, but can be correlated in time. We characterize the system throughput asymptotically in n. Specifically, we explicitly show how the throughput behaves for different values of the coding block size K as a function of n, as n approaches infinity. Under the more restrictive assumption of memoryless channels, we are able to provide a lower bound on the maximum achievable throughput for any finite values of K and n. Using simulations we show the tightness of the bound with respect to system parameters n and K, and find that its performance is significantly better than the previously known lower bound.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2011</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr">
<abbr class="badge">INFOCOM</abbr><div class="teaser"></div>

        </div>

        <!-- Entry bib key -->
        <div id="delay_asymptotics_fixed_rate_coding" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Delay asymptotics with retransmissions and fixed rate codes over erasure channels</div>
          <!-- Author -->
          <div class="author">
<a href="https://scholar.google.com/citations?hl=en&amp;user=m36rOvoAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="noopener noreferrer">Tan, Jian</a>, 
                  <em>Yang, Yang</em>, <a href="http://newslab.ece.ohio-state.edu/home/index.html" target="_blank" rel="noopener noreferrer">Shroff, Ness B.</a>, and El Gamal, Hesham
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In IEEE INFOCOM</em> 2011
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://ieeexplore.ieee.org/document/5934907" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2022 Yang  Yang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.
Last updated: May 25, 2022.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123722738-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'UA-123722738-1');
  </script>
  </body>
</html>

